# FA_768の方(re2_lstm_f0のデータを、rinna_F_Aに変更、バッチサイズをファイル行数に修正、データローダ作成)
# re5_rinna_F_A_prepared_features_dataを作成
import pandas as pd
import numpy as np
import glob
import os
import torch
# データのロードと整形を行う関数
def load_and_preprocess_data(folder_path):
    # 指定したフォルダー内のCSVファイルを全て取得
    csv_files = [f"{folder_path}/BASIC5000_{i:04d}_features.csv" for i in range(1, 5001)]
    
    audio_data = {}

    # 各CSVファイルを読み込み
    for file in csv_files:
        # CSVファイルをDataFrameとして読み込み
        df = pd.read_csv(file)
        
        # F0特徴量 (Feature_0 〜 Feature_767) とアクセントを抽出
        feature_columns = [f'Feature_{i}' for i in range(768)]  # Feature_0 〜 Feature_767
        data = df[feature_columns + ['Accent']].values  # 特徴量とアクセントを取得
        
        # ファイル名から音声IDを取得
        audio_id = os.path.basename(file).split('.')[0]  # 例: 'f0_statistics_1'

        # 音声IDをキーとしてデータを辞書に格納
        audio_data[audio_id] = data

    return audio_data

# データのロード
audio_data = load_and_preprocess_data('rinna_F_A')

# 特徴量とラベルに分け、PyTorchのテンソルに変換する関数
def prepare_data(audio_data):
    X_list = []
    y_list = []
    
    for audio_id, data in audio_data.items():
        # 特徴量とラベルを分ける
        X = data[:, :-1]  # 特徴量（Feature_0 〜 Feature_767）
        y = data[:, -1]   # ラベル（Accent）

        # 各音声データの特徴量とラベルをリストに追加
        X_list.append(X)
        y_list.append(y)

    # リストをPyTorchのテンソルに変換
    X_tensor = [torch.tensor(X, dtype=torch.float32) for X in X_list]
    y_tensor = [torch.tensor(y, dtype=torch.long) for y in y_list]

    return X_tensor, y_tensor

# 特徴量とラベルを準備する
X_tensor, y_tensor = prepare_data(audio_data)

# データの確認
for i in range(len(X_tensor)):
    print(f"Audio ID: {i + 1}, Feature shape: {X_tensor[i].shape}, Label shape: {y_tensor[i].shape}")

# データを保存する（必要に応じて）  
def save_data(X_tensor, y_tensor, output_folder):
    os.makedirs(output_folder, exist_ok=True)

    for i, (X, y) in enumerate(zip(X_tensor, y_tensor)):
        # 特徴量とラベルをCSVファイルとして保存
        df_X = pd.DataFrame(X.numpy(), columns=[f'Feature_{i}' for i in range(768)])  # Feature_0 〜 Feature_767
        df_y = pd.DataFrame(y.numpy(), columns=['Accent'])
        
        df_X.to_csv(os.path.join(output_folder, f"features_audio_{i + 1}.csv"), index=False)
        df_y.to_csv(os.path.join(output_folder, f"labels_audio_{i + 1}.csv"), index=False)

# 特徴量とラベルを保存（必要に応じて）
save_data(X_tensor, y_tensor, 're5_rinna_F_A_prepared_features_data')

print("データの準備と保存が完了しました。")

# 訓練4500, 評価500
import pandas as pd
import os
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from tqdm import tqdm  # 進捗バー表示のためにtqdmをインポート
import matplotlib.pyplot as plt

# データをロードする関数
def load_csv_data(folder_path, num_files=5000):
    X_list = []
    y_list = []

    for i in range(1, num_files + 1):
        # 特徴量を読み込む
        features_file = os.path.join(folder_path, f"features_audio_{i}.csv")
        labels_file = os.path.join(folder_path, f"labels_audio_{i}.csv")

        df_X = pd.read_csv(features_file)
        df_y = pd.read_csv(labels_file)

        # DataFrameからnumpy配列に変換し、PyTorchのTensorに変換
        X = torch.tensor(df_X.values, dtype=torch.float32)
        y = torch.tensor(df_y.values.flatten(), dtype=torch.long)

        X_list.append(X)
        y_list.append(y)

    return X_list, y_list

# 特徴量とラベルのロード
folder_path = 're5_rinna_F_A_prepared_features_data'
X_list, y_list = load_csv_data(folder_path)

# データを学習用と評価用に分ける関数
def split_data(X_list, y_list, test_size=0.1, random_state=42):
    X_train, X_test, y_train, y_test = train_test_split(X_list, y_list, test_size=test_size, random_state=random_state)
    return X_train, X_test, y_train, y_test

# 学習データと評価データに分割
X_train, X_test, y_train, y_test = split_data(X_list, y_list)

# LSTMモデル定義
class LSTMAccentModel(nn.Module):
    def __init__(self, input_size, hidden_size, output_size, num_layers=1):
        super(LSTMAccentModel, self).__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)
    
    def forward(self, x):
        out, _ = self.lstm(x)  # LSTMの出力
        out = self.fc(out)  # 全ての時間ステップの出力を使用
        return out

# モデル学習のための関数
def train_model(model, X_train, y_train, num_epochs=100, learning_rate=0.001):
    criterion = nn.CrossEntropyLoss()  # 損失関数
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    
    losses = []  # 各エポックの損失を記録するリスト

    for epoch in range(num_epochs):
        total_loss = 0.0
        
        # tqdmでエポック全体の進捗バーを表示（全バッチを100%とする）
        with tqdm(total=len(X_train), desc=f"Epoch {epoch+1}/{num_epochs}", unit="batch") as pbar:
            for i, (inputs, labels) in enumerate(zip(X_train, y_train)):
                # バッチ化されたデータをモデルに渡して予測を取得
                inputs = inputs.unsqueeze(0)  # バッチ次元を追加
                labels = labels.view(-1)  # ラベルを1次元に変換
                
                outputs = model(inputs)
                
                # 出力とラベルの形を一致させる
                outputs = outputs.view(-1, outputs.size(-1))
                
                # 損失計算
                loss = criterion(outputs, labels)
                total_loss += loss.item()
                
                # バックプロパゲーション
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

                # バッチごとに進捗を更新
                pbar.update(1)

        # 各エポックの平均損失を保存
        avg_loss = total_loss / len(X_train)
        losses.append(avg_loss)

        # 各エポックの平均損失を出力
        print(f"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}")

    # 学習の進行状況をプロット
    plt.plot(range(1, num_epochs + 1), losses, label='Training Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Training Loss over Epochs')
    plt.legend()
    plt.show()

# モデルの初期化（ラベルが0, 1, 2の場合は output_size = 3 とする）
input_size = 768  # 特徴量の数
hidden_size = 64  # 隠れ層のユニット数
output_size = 2  # ラベルの範囲が 0, 1, 2 ならば output_size = 3
num_layers = 3  # LSTMのレイヤー数

model = LSTMAccentModel(input_size, hidden_size, output_size)

# データのロード（前に定義した `X_tensor` と `y_tensor` を使用）
X_train = X_tensor  # 特徴量
y_train = y_tensor  # ラベル

# モデルの学習を実行
train_model(model, X_train, y_train)

# re5_LSTM_F0.ipynbと同じコード
# 正解ラベルと予測結果を保存
import os
import pandas as pd
import torch

# 保存するフォルダの作成
output_dir = 'predicted_re5_L_FA_768'
os.makedirs(output_dir, exist_ok=True)

# 評価関数の修正: 予測結果をCSVファイルに保存
def save_predictions_to_csv(model, X_test, y_test, output_dir):
    model.eval()  # 評価モードに切り替え

    with torch.no_grad():  # 勾配計算を無効に
        for i, (inputs, labels) in enumerate(zip(X_test, y_test)):
            inputs = inputs.unsqueeze(0)  # バッチ次元を追加
            outputs = model(inputs)
            _, predicted = torch.max(outputs, 2)  # 最も高いスコアを持つクラスを選択
            
            # 予測結果と正解ラベルをTensorからNumPy配列に変換
            true_labels_np = labels.view(-1).numpy()  # 正解ラベル
            predicted_np = predicted.view(-1).numpy()  # 予測ラベル
            
            # CSVファイルに保存
            file_name = os.path.join(output_dir, f'predicted_accent_{i+1}.csv')
            result_df = pd.DataFrame({
                'True Accent': true_labels_np,
                'Predicted Accent': predicted_np
            })
            result_df.to_csv(file_name, index=False)

# 予測結果を保存
save_predictions_to_csv(model, X_test, y_test, output_dir)

print(f"Predicted accents and true accents saved in the '{output_dir}' directory.")

# re5_LSTM_F0.ipynbと同じコード
# 一致率の算出(多分、再現率)
import os
import pandas as pd
import torch

# フォルダのパスを指定
predicted_dir = 'predicted_re5_L_FA_768'

# y_testをリストに変換する関数
def load_y_test_tensor(y_test):
    return [tensor.numpy() for tensor in y_test]  # TensorをNumPy配列に変換してリストに追加

# y_testをリスト形式でロード
y_test_list = load_y_test_tensor(y_test)

# 一致数をカウントするための変数を初期化
total_matches = 0
total_samples = 0
match_class_0 = 0
match_class_1 = 0

# 各クラスの総数をカウントするための変数を初期化
total_class_0 = 0
total_class_1 = 0

# 予測結果をロードして一致をカウント
for i in range(1, 500):  # predicted_accent_1.csv から predicted_accent_500.csv まで
    file_name = os.path.join(predicted_dir, f'predicted_accent_{i}.csv')
    
    if os.path.exists(file_name):
        # CSVファイルを読み込む
        predicted_df = pd.read_csv(file_name)
        predicted_array = predicted_df['Predicted Accent'].to_numpy()

        # 一致数をカウント
        if i <= len(y_test_list):  # y_testの範囲内であるか確認
            total_matches += (predicted_array == y_test_list[i - 1]).sum()
            total_samples += len(predicted_array)

            # クラス0とクラス1の一致数と総数をカウント
            match_class_0 += ((predicted_array == 0) & (y_test_list[i - 1] == 0)).sum()
            match_class_1 += ((predicted_array == 1) & (y_test_list[i - 1] == 1)).sum()

            total_class_0 += (y_test_list[i - 1] == 0).sum()
            total_class_1 += (y_test_list[i - 1] == 1).sum()

# 各クラスの一致率を計算
accuracy_class_0 = match_class_0 / total_class_0 if total_class_0 > 0 else 0
accuracy_class_1 = match_class_1 / total_class_1 if total_class_1 > 0 else 0

# 結果を出力
print(f'(下降)クラス0の一致数: {match_class_0} / クラス0の総数: {total_class_0} / 一致率: {match_class_0}/{total_class_0} = {accuracy_class_0:.4f}')
print(f'(上昇)クラス1の一致数: {match_class_1} / クラス1の総数: {total_class_1} / 一致率: {match_class_1}/{total_class_1} = {accuracy_class_1:.4f}')

# re5_LSTM_F0.ipynbと同じコード
# 一致数をカウントするための変数を初期化
TP_0 = 0  # クラス0のTrue Positive
FP_0 = 0  # クラス0のFalse Positive
FN_0 = 0  # クラス0のFalse Negative
TN_0 = 0  # クラス0のTrue Negative

TP_1 = 0  # クラス1のTrue Positive
FP_1 = 0  # クラス1のFalse Positive
FN_1 = 0  # クラス1のFalse Negative
TN_1 = 0  # クラス1のTrue Negative

# 予測結果をロードして一致をカウント
for i in range(1, 500):  # predicted_accent_1.csv から predicted_accent_500.csv まで
    file_name = os.path.join(predicted_dir, f'predicted_accent_{i}.csv')

    if os.path.exists(file_name):
        # CSVファイルを読み込む
        predicted_df = pd.read_csv(file_name)
        predicted_array = predicted_df['Predicted Accent'].to_numpy()

        if i <= len(y_test_list):  # y_testの範囲内であるか確認
            actual_array = y_test_list[i - 1]

            # クラス0に関するカウント
            TP_0 += ((predicted_array == 0) & (actual_array == 0)).sum()
            FP_0 += ((predicted_array == 0) & (actual_array == 1)).sum()
            FN_0 += ((predicted_array == 1) & (actual_array == 0)).sum()
            TN_0 += ((predicted_array == 1) & (actual_array == 1)).sum()

            # クラス1に関するカウント
            TP_1 += ((predicted_array == 1) & (actual_array == 1)).sum()
            FP_1 += ((predicted_array == 1) & (actual_array == 0)).sum()
            FN_1 += ((predicted_array == 0) & (actual_array == 1)).sum()
            TN_1 += ((predicted_array == 0) & (actual_array == 0)).sum()

# 再現率、適合率、F値の計算
# クラス0
recall_0 = TP_0 / (TP_0 + FN_0) if (TP_0 + FN_0) > 0 else 0
precision_0 = TP_0 / (TP_0 + FP_0) if (TP_0 + FP_0) > 0 else 0
f1_0 = 2 * (precision_0 * recall_0) / (precision_0 + recall_0) if (precision_0 + recall_0) > 0 else 0

# クラス1
recall_1 = TP_1 / (TP_1 + FN_1) if (TP_1 + FN_1) > 0 else 0
precision_1 = TP_1 / (TP_1 + FP_1) if (TP_1 + FP_1) > 0 else 0
f1_1 = 2 * (precision_1 * recall_1) / (precision_1 + recall_1) if (precision_1 + recall_1) > 0 else 0

# 結果を出力
print(f'(下降)クラス0の再現率: {recall_0:.4f}, 適合率: {precision_0:.4f}, F1スコア: {f1_0:.4f}')
print(f'(上昇)クラス1の再現率: {recall_1:.4f}, 適合率: {precision_1:.4f}, F1スコア: {f1_1:.4f}')

# re5_LSTM_F0.ipynbと同じコード
# アクセント上昇・下降位置の再現率、適合率、F値
# 上昇・下降位置における再現率、適合率、F値を算出
# アクセント上昇、下降位置における
# 一致率、再現率、適合率、F値
import os
import csv
from sklearn.metrics import recall_score, precision_score, f1_score

# combined_predictions ディレクトリ
combined_predictions_dir = "predicted_re5_L_FA_768"
output_results_dir = "results"      # これは無視！
os.makedirs(output_results_dir, exist_ok=True)

# 集計用の変数
total_up = total_down = correct_up = correct_down = 0
true_labels_all = []
predicted_labels_all = []

# combined_predictions ディレクトリ内のファイルを順に処理
for prediction_file in os.listdir(combined_predictions_dir):
    if prediction_file.endswith(".csv"):
        prediction_file_path = os.path.join(combined_predictions_dir, prediction_file)

        true_labels = []
        predicted_labels = []

        # True Label, Predicted Label 列を読み込み
        with open(prediction_file_path, mode='r', newline='', encoding='utf-8') as file:
            reader = csv.DictReader(file)
            
            # ヘッダー情報を表示
            # print(f"Headers in {prediction_file}: {reader.fieldnames}")   # デバッグ用
            
            for row in reader:
                # ヘッダーに応じて列名を指定（ここを調整する必要がある場合あり）
                true_labels.append(int(row["True Accent"]))  # "True Label" に変更
                predicted_labels.append(int(row["Predicted Accent"]))  # "Predicted Label" に変更

        # アクセント変化を検出
        true_changes = []
        predicted_changes = []

        for i in range(1, len(true_labels)):
            # True Label の変化 (アクセント上昇、下降)
            if true_labels[i-1] == 0 and true_labels[i] == 1:
                true_changes.append('up')
            elif true_labels[i-1] == 1 and true_labels[i] == 0:
                true_changes.append('down')
            else:
                true_changes.append('no_change')

            # Predicted Label の変化 (アクセント上昇、下降)
            if predicted_labels[i-1] == 0 and predicted_labels[i] == 1:
                predicted_changes.append('up')
            elif predicted_labels[i-1] == 1 and predicted_labels[i] == 0:
                predicted_changes.append('down')
            else:
                predicted_changes.append('no_change')

        # アクセント上昇、下降の一致率を計算
        for true, pred in zip(true_changes, predicted_changes):
            if true == 'up':
                total_up += 1
                if pred == 'up':
                    correct_up += 1
            elif true == 'down':
                total_down += 1
                if pred == 'down':
                    correct_down += 1

        # 全体の真のラベルと予測ラベルを収集
        true_labels_all.extend(true_labels)
        predicted_labels_all.extend(predicted_labels)

# 一致率を計算
accuracy_up = correct_up / total_up if total_up > 0 else 0
accuracy_down = correct_down / total_down if total_down > 0 else 0

# 再現率、適合率、F1スコアを計算
recall_up = recall_score(true_labels_all, predicted_labels_all, pos_label=1)
precision_up = precision_score(true_labels_all, predicted_labels_all, pos_label=1)
f1_up = f1_score(true_labels_all, predicted_labels_all, pos_label=1)

recall_down = recall_score(true_labels_all, predicted_labels_all, pos_label=0)
precision_down = precision_score(true_labels_all, predicted_labels_all, pos_label=0)
f1_down = f1_score(true_labels_all, predicted_labels_all, pos_label=0)

# 結果の表示
print(f"Total Up Changes: {total_up}, Correct Up Predictions: {correct_up}, Accuracy (Up): {accuracy_up:.4f}")
print(f"Total Down Changes: {total_down}, Correct Down Predictions: {correct_down}, Accuracy (Down): {accuracy_down:.4f}")

print(f"Recall (Up): {recall_up:.4f}")
print(f"Precision (Up): {precision_up:.4f}")
print(f"F1 Score (Up): {f1_up:.4f}")

print(f"Recall (Down): {recall_down:.4f}")
print(f"Precision (Down): {precision_down:.4f}")
print(f"F1 Score (Down): {f1_down:.4f}")
