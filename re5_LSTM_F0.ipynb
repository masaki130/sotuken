# 学習データを特徴量とアクセントのファイルに分ける！
# 入力；f0_stac_result_5000
# 出力；prepared_features_dataとして保存
# 特徴量とアクセントの統合データを特徴量だけとアクセントだけのファイルに分けた！
import pandas as pd
import numpy as np
import glob
import os
import torch

# データのロードと整形を行う関数
def load_and_preprocess_data(folder_path):
    # 指定したフォルダー内のCSVファイルを全て取得
    csv_files = [f"{folder_path}/fix_f0_statistics_{i}.csv" for i in range(1, 5001)]
    
    audio_data = {}

    # 各CSVファイルを読み込み
    for file in csv_files:
        # CSVファイルをDataFrameとして読み込み
        df = pd.read_csv(file)
        
        # 特徴量とラベルを抽出
        data = df[['Mean', 'Max', 'Min', 'Std', 'Median', 'Accent']].values
        
        # ファイル名から音声IDを取得
        audio_id = os.path.basename(file).split('.')[0]  # 例: 'f0_statistics_1'

        # 音声IDをキーとしてデータを辞書に格納
        audio_data[audio_id] = data

    return audio_data

# データのロード
audio_data = load_and_preprocess_data('fix_f0_stac_result_5000')    # Mora, Mean, Max, Min, Std, Median, Accent

# 特徴量とラベルに分け、PyTorchのテンソルに変換する関数
def prepare_data(audio_data):
    X_list = []
    y_list = []
    
    for audio_id, data in audio_data.items():
        # 特徴量とラベルを分ける
        X = data[:, :-1]  # 特徴量（Mean, Max, Min, Std, Median）
        y = data[:, -1]   # ラベル（Accent）

        # 各音声データの特徴量とラベルをリストに追加
        X_list.append(X)
        y_list.append(y)

    # リストをPyTorchのテンソルに変換
    X_tensor = [torch.tensor(X, dtype=torch.float32) for X in X_list]
    y_tensor = [torch.tensor(y, dtype=torch.long) for y in y_list]

    return X_tensor, y_tensor

# 特徴量とラベルを準備する
X_tensor, y_tensor = prepare_data(audio_data)

# データの確認
for i in range(len(X_tensor)):
    print(f"Audio ID: {i + 1}, Feature shape: {X_tensor[i].shape}, Label shape: {y_tensor[i].shape}")

# データを保存する（必要に応じて）
def save_data(X_tensor, y_tensor, output_folder):
    os.makedirs(output_folder, exist_ok=True)

    for i, (X, y) in enumerate(zip(X_tensor, y_tensor)):
        # 特徴量とラベルをCSVファイルとして保存
        df_X = pd.DataFrame(X.numpy(), columns=['Mean', 'Max', 'Min', 'Std', 'Median'])
        df_y = pd.DataFrame(y.numpy(), columns=['Accent'])
        
        df_X.to_csv(os.path.join(output_folder, f"features_audio_{i + 1}.csv"), index=False)
        df_y.to_csv(os.path.join(output_folder, f"labels_audio_{i + 1}.csv"), index=False)

# 特徴量とラベルを保存（必要に応じて）
save_data(X_tensor, y_tensor, 'fix_f0_prepared_features_data')  # 全データを特徴量とアクセントのファイルにそれぞれ分ける(合ってる！)

print("データの準備と保存が完了しました。")

import pandas as pd
import os
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from torch.utils.data import DataLoader, TensorDataset
from tqdm import tqdm  # 進捗バー表示のためにtqdmをインポート
import matplotlib.pyplot as plt

# データをロードする関数
def load_csv_data(folder_path, num_files=5000):
    X_list = []
    y_list = []

    for i in range(1, num_files + 1):
        # 特徴量を読み込む
        features_file = os.path.join(folder_path, f"features_audio_{i}.csv")
        labels_file = os.path.join(folder_path, f"labels_audio_{i}.csv")

        df_X = pd.read_csv(features_file)
        df_y = pd.read_csv(labels_file)

        # DataFrameからnumpy配列に変換し、PyTorchのTensorに変換
        X = torch.tensor(df_X.values, dtype=torch.float32)
        y = torch.tensor(df_y.values.flatten(), dtype=torch.long)

        X_list.append(X)
        y_list.append(y)

    return X_list, y_list

# 特徴量とラベルのロード
folder_path = 'fix_f0_prepared_features_data'
X_list, y_list = load_csv_data(folder_path)

# データを学習用と評価用に分ける関数
def split_data(X_list, y_list, test_size=0.1, random_state=42):
    X_train, X_test, y_train, y_test = train_test_split(X_list, y_list, test_size=test_size, random_state=random_state)
    return X_train, X_test, y_train, y_test

# 学習データと評価データに分割
X_train, X_test, y_train, y_test = split_data(X_list, y_list)

# LSTMモデル定義
class LSTMAccentModel(nn.Module):
    def __init__(self, input_size, hidden_size, output_size, num_layers=1):
        super(LSTMAccentModel, self).__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)
    
    def forward(self, x):
        out, _ = self.lstm(x)  # LSTMの出力
        out = self.fc(out)  # 全ての時間ステップの出力を使用
        return out

# モデル学習のための関数
def train_model(model, train_loader_list, num_epochs=100, learning_rate=0.001):
    criterion = nn.CrossEntropyLoss()  # 損失関数
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    
    losses = []  # 各エポックの損失を記録するリスト

    # tqdmでエポック全体の進捗バーを表示（全バッチを100%とする）
    total_batches = sum([len(loader) for loader in train_loader_list])  # すべてのDataLoaderのバッチ数を合計
    with tqdm(total=total_batches, desc=f"Training", unit="batch") as pbar:
        for epoch in range(num_epochs):
            total_loss = 0.0
            for train_loader in train_loader_list:
                for inputs, labels in train_loader:
                    # バッチ処理（バッチサイズはそのファイルの行数）
                    outputs = model(inputs)
                    outputs = outputs.view(-1, outputs.size(-1))  # 出力の形を整える
                    loss = criterion(outputs, labels)
                    total_loss += loss.item()

                    # バックプロパゲーション
                    optimizer.zero_grad()
                    loss.backward()
                    optimizer.step()

                    # バッチごとに進捗を更新
                    pbar.update(1)

            # 各エポックの平均損失を保存
            avg_loss = total_loss / len(train_loader_list)
            losses.append(avg_loss)

            # 各エポックの平均損失を出力
            print(f"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}")
    
    return losses

# 訓練データのためのDataLoader作成
train_dataset_list = []

# 各ファイルに対してDataLoaderを作成
for i in range(len(X_train)):
    # 各ファイルの特徴量とラベル
    x_data = X_train[i]
    y_data = y_train[i]

    # TensorDatasetを作成
    train_dataset = TensorDataset(x_data, y_data)

    # DataLoaderを作成 (バッチサイズはそのファイルの行数)
    batch_size = x_data.size(0)  # ファイルの行数をバッチサイズに設定
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    
    # DataLoaderをリストに追加
    train_dataset_list.append(train_loader)

# モデルの初期化（ラベルが0, 1の場合は output_size = 2 とする）
input_size = X_train[0].size(1)  # 特徴量の数（例えば、各特徴量が 768 次元）
hidden_size = 64  # 隠れ層のユニット数
output_size = 2  # ラベルの範囲が 0, 1 の場合は output_size = 2
num_layers = 3  # LSTMのレイヤー数 1⇒3

model = LSTMAccentModel(input_size, hidden_size, output_size)

# モデルの学習を実行
num_epochs = 100  # エポック数を指定
learning_rate = 0.001  # 学習率を指定

losses = train_model(model, train_dataset_list, num_epochs=num_epochs, learning_rate=learning_rate)

# 学習の進行状況をプロット
plt.plot(range(1, num_epochs + 1), losses, label='Training Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss over Epochs')
plt.legend()
plt.show()

import pandas as pd
import os
import torch
from torch.utils.data import DataLoader, TensorDataset
from sklearn.metrics import precision_score, recall_score, f1_score

# 評価用データを準備する
def prepare_eval_data(X_test, y_test):
    eval_dataset_list = []

    # 各ファイルに対してDataLoaderを作成
    for i in range(len(X_test)):
        # 各ファイルの特徴量とラベル
        x_data = X_test[i]
        y_data = y_test[i]

        # TensorDatasetを作成
        eval_dataset = TensorDataset(x_data, y_data)

        # DataLoaderを作成 (バッチサイズはそのファイルの行数)
        batch_size = x_data.size(0)  # ファイルの行数をバッチサイズに設定
        eval_loader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=False)
        
        # DataLoaderをリストに追加
        eval_dataset_list.append(eval_loader)

    return eval_dataset_list


# 評価用データでモデルをテストし、予測結果を保存する関数
def evaluate_model(model, eval_loader_list, output_dir="re5_results_L_F0_5"):   #5⇒6
    # 出力ディレクトリが存在しない場合は作成
    os.makedirs(output_dir, exist_ok=True)

    model.eval()  # 評価モードに設定

    # 予測結果と正解ラベルを集める
    all_true_labels = []
    all_pred_labels = []

    # 各ファイルごとに予測結果を保存
    with torch.no_grad():  # 勾配計算を停止
        for i, eval_loader in enumerate(eval_loader_list):
            all_predictions = []  # 予測結果を保存するリスト
            all_labels = []  # 正解ラベルを保存するリスト
            
            for inputs, labels in eval_loader:
                outputs = model(inputs)  # モデルで予測

                # 出力の最も確率が高いクラスを予測として取得
                _, predicted = torch.max(outputs, 1)

                # 予測結果と正解ラベルを保存
                all_predictions.extend(predicted.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())

            # 結果をDataFrameに保存
            evaluation_results = pd.DataFrame({
                "True_Label": all_labels,
                "Predicted_Label": all_predictions
            })

            # 各ファイルに対して保存 (ファイル名を 'evaluation_result_{i}.csv' にする)
            output_file = os.path.join(output_dir, f"evaluation_result_{i+1}.csv")
            evaluation_results.to_csv(output_file, index=False)

            print(f"Evaluation results for file {i+1} saved to {output_file}")

            # 予測結果と正解ラベルをまとめていく
            all_true_labels.extend(all_labels)
            all_pred_labels.extend(all_predictions)

    # Precision, Recall, F1-Scoreの計算（クラスごとに）
    precision_per_class = precision_score(all_true_labels, all_pred_labels, average=None)
    recall_per_class = recall_score(all_true_labels, all_pred_labels, average=None)
    f1_per_class = f1_score(all_true_labels, all_pred_labels, average=None)

    # クラスごとのスコアを表示
    print("\nClass-wise Precision, Recall, F1-Score:")
    for i in range(len(precision_per_class)):
        print(f"Class {i} - Precision: {precision_per_class[i]:.4f}, Recall: {recall_per_class[i]:.4f}, F1-Score: {f1_per_class[i]:.4f}")

    # 加重平均を計算
    precision_weighted = precision_score(all_true_labels, all_pred_labels, average='weighted')
    recall_weighted = recall_score(all_true_labels, all_pred_labels, average='weighted')
    f1_weighted = f1_score(all_true_labels, all_pred_labels, average='weighted')

    # 最終的な結果を標準出力
    # print("\nOverall Evaluation Metrics (Weighted Average):")
    # print(f"Precision: {precision_weighted:.4f}")
    # print(f"Recall: {recall_weighted:.4f}")
    # print(f"F1-Score: {f1_weighted:.4f}")

    return precision_per_class, recall_per_class, f1_per_class, precision_weighted, recall_weighted, f1_weighted


# 評価用データの準備
eval_loader_list = prepare_eval_data(X_test, y_test)

# モデルの評価を実行
evaluate_model(model, eval_loader_list, output_dir="re5_results_L_F0_6")    #5⇒6

# アクセント上昇、下降位置における
# 一致率、再現率、適合率、F値
import os
import csv
from sklearn.metrics import recall_score, precision_score, f1_score

# combined_predictions ディレクトリ
combined_predictions_dir = "re5_results_L_F0_5"
output_results_dir = "results_L_F0_5"
os.makedirs(output_results_dir, exist_ok=True)

# 集計用の変数
total_up = total_down = correct_up = correct_down = 0
true_labels_all = []
predicted_labels_all = []

# combined_predictions ディレクトリ内のファイルを順に処理
for prediction_file in os.listdir(combined_predictions_dir):
    if prediction_file.endswith(".csv"):
        prediction_file_path = os.path.join(combined_predictions_dir, prediction_file)

        true_labels = []
        predicted_labels = []

        # True Label, Predicted Label 列を読み込み
        with open(prediction_file_path, mode='r', newline='', encoding='utf-8') as file:
            reader = csv.DictReader(file)
            
            # ヘッダー情報を表示
            # print(f"Headers in {prediction_file}: {reader.fieldnames}")   # デバッグ用
            
            for row in reader:
                # ヘッダーに応じて列名を指定（ここを調整する必要がある場合あり）
                true_labels.append(int(row["True_Label"]))  # "True Label" に変更
                predicted_labels.append(int(row["Predicted_Label"]))  # "Predicted Label" に変更

        # アクセント変化を検出
        true_changes = []
        predicted_changes = []

        for i in range(1, len(true_labels)):
            # True Label の変化 (アクセント上昇、下降)
            if true_labels[i-1] == 0 and true_labels[i] == 1:
                true_changes.append('up')
            elif true_labels[i-1] == 1 and true_labels[i] == 0:
                true_changes.append('down')
            else:
                true_changes.append('no_change')

            # Predicted Label の変化 (アクセント上昇、下降)
            if predicted_labels[i-1] == 0 and predicted_labels[i] == 1:
                predicted_changes.append('up')
            elif predicted_labels[i-1] == 1 and predicted_labels[i] == 0:
                predicted_changes.append('down')
            else:
                predicted_changes.append('no_change')

        # アクセント上昇、下降の一致率を計算
        for true, pred in zip(true_changes, predicted_changes):
            if true == 'up':
                total_up += 1
                if pred == 'up':
                    correct_up += 1
            elif true == 'down':
                total_down += 1
                if pred == 'down':
                    correct_down += 1

        # 全体の真のラベルと予測ラベルを収集
        true_labels_all.extend(true_labels)
        predicted_labels_all.extend(predicted_labels)

# 一致率を計算
accuracy_up = correct_up / total_up if total_up > 0 else 0
accuracy_down = correct_down / total_down if total_down > 0 else 0

# 再現率、適合率、F1スコアを計算
recall_up = recall_score(true_labels_all, predicted_labels_all, pos_label=1)
precision_up = precision_score(true_labels_all, predicted_labels_all, pos_label=1)
f1_up = f1_score(true_labels_all, predicted_labels_all, pos_label=1)

recall_down = recall_score(true_labels_all, predicted_labels_all, pos_label=0)
precision_down = precision_score(true_labels_all, predicted_labels_all, pos_label=0)
f1_down = f1_score(true_labels_all, predicted_labels_all, pos_label=0)

# 結果の表示
print(f"Total Up Changes: {total_up}, Correct Up Predictions: {correct_up}, Accuracy (Up): {accuracy_up:.4f}")
print(f"Total Down Changes: {total_down}, Correct Down Predictions: {correct_down}, Accuracy (Down): {accuracy_down:.4f}")

print(f"Recall (Up): {recall_up:.4f}")
print(f"Precision (Up): {precision_up:.4f}")
print(f"F1 Score (Up): {f1_up:.4f}")

print(f"Recall (Down): {recall_down:.4f}")
print(f"Precision (Down): {precision_down:.4f}")
print(f"F1 Score (Down): {f1_down:.4f}")
