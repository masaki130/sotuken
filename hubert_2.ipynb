# rinnaのHuBERTを使用
# 量産
# 保存先；basic5000_jp_HuBERT_features_csv
import os
import pandas as pd
import torch
import numpy as np
import soundfile as sf
from transformers import AutoFeatureExtractor, AutoModel
from scipy.signal import resample_poly
from tqdm import tqdm

# rinna/japanese-hubert-baseモデルをロードする関数
def load_hubert_model():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model_name = "rinna/japanese-hubert-base"
    feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)
    model = AutoModel.from_pretrained(model_name)
    model = model.to(device).eval()
    return model, feature_extractor, device

# 音声ファイルを16000Hzにリサンプリングする関数
def resample_audio(audio, original_sr, target_sr=16000):
    if original_sr != target_sr:
        # リサンプリング
        audio_resampled = resample_poly(audio, target_sr, original_sr)
        return audio_resampled
    return audio

# 音声ファイルからHuBERT特徴量を抽出する関数
def extract_hubert_features(audio_path, model, feature_extractor, device):
    # 音声ファイルを読み込む
    raw_speech_16kHz, sr = sf.read(audio_path)

    # サンプリングレートを16000Hzにリサンプリング
    raw_speech_16kHz = resample_audio(raw_speech_16kHz, sr)

    # 特徴量の抽出
    inputs = feature_extractor(
        raw_speech_16kHz,
        return_tensors="pt",
        sampling_rate=16000,  # 必ず16000Hzとして渡す
    )
    inputs = inputs.to(device)
    
    # モデルで特徴量を取得
    with torch.no_grad():
        outputs = model(**inputs)

    return outputs.last_hidden_state.squeeze(0).cpu().numpy()  # 特徴量をNumPy配列として返す

# アライメント情報を使用して音節ごとの特徴量を抽出する関数
def extract_features_by_alignment(features, alignment_path, sample_rate=16000, hop_length=320):
    alignment = pd.read_csv(alignment_path)
    extracted_features = []
    for _, row in alignment.iterrows():
        start_frame = int(row['Start (s)'] * sample_rate // hop_length)
        end_frame = int(row['End (s)'] * sample_rate // hop_length)
        mora_features = features[start_frame:end_frame].mean(axis=0)  # 平均を計算
        extracted_features.append({
            "Mora": row['Mora'],
            **{f"Feature_{i}": value for i, value in enumerate(mora_features)}
        })
    return extracted_features

# 音声ファイルとアライメント情報を組み合わせて処理する関数
def process_audio_and_alignment(input_audio_dir, alignment_dir, output_dir, model, feature_extractor, device, num_files=None):
    audio_files = sorted([f for f in os.listdir(input_audio_dir) if f.endswith(".wav")])
    if num_files is not None:
        audio_files = audio_files[:num_files]
    os.makedirs(output_dir, exist_ok=True)

    # tqdmを使ってファイル作成数の進行状況バーを表示
    with tqdm(total=len(audio_files), desc="Files Processed") as pbar:
        for audio_file in audio_files:
            audio_path = os.path.join(input_audio_dir, audio_file)
            alignment_file = f"alignment_{audio_file.replace('BASIC5000_', '').replace('.wav', '.csv')}"
            alignment_path = os.path.join(alignment_dir, alignment_file)
            output_path = os.path.join(output_dir, alignment_file)

            if not os.path.exists(alignment_path):
                # print(f"Alignment file not found: {alignment_path}")
                continue

            # print(f"Processing {audio_path} with {alignment_path}...")

            # HuBERT特徴量を抽出
            features = extract_hubert_features(audio_path, model, feature_extractor, device)

            # 音節ごとの特徴量を抽出
            extracted_features = extract_features_by_alignment(features, alignment_path)

            # CSV形式で保存
            pd.DataFrame(extracted_features).to_csv(output_path, index=False)
            # print(f"Saved features to {output_path}")
            
            # 処理したファイル数を進捗バーに反映
            pbar.update(1)

# メイン処理
if __name__ == "__main__":
    input_audio_directory = "./basic5000"  # 音声ファイルのディレクトリ
    alignment_directory = "./align_result_5000"  # アライメント情報のディレクトリ
    output_directory = "./basic5000_jp_HuBERT_features_csv"  # 特徴量を保存するディレクトリ
    num_files_to_process = 5000  # 任意の処理ファイル数（例: 上から100個）

    # HuBERTモデルのロード
    hubert_model, feature_extractor, device = load_hubert_model()

    # 音声とアライメント情報を組み合わせて処理
    process_audio_and_alignment(
        input_audio_directory,
        alignment_directory,
        output_directory,
        hubert_model,
        feature_extractor,
        device,
        num_files=num_files_to_process
    )
